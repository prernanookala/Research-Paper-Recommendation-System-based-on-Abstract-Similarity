{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from collections import Counter\n",
    "import dask.bag as db\n",
    "import string\n",
    "import numpy as np\n",
    "import json\n",
    "import pyarrow as pa\n",
    "import lancedb\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from sklearn.cluster import KMeans\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mounting Drive to access the JSON dataset file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.bag as db\n",
    "import json\n",
    "file_name = db.read_text('/content/drive/MyDrive/arxiv-metadata-oai-snapshot.json').map(json.loads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Stratified Sample of 100K records based on the category in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4HnPMxzxCxL3",
    "outputId": "c203b6a2-290d-49c0-b278-055b7f6219e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique categories: 149\n",
      "Unique categories:\n",
      "['hep-ph', 'physics.gen-ph', 'math.CO', 'cond-mat.mes-hall', 'gr-qc', 'cond-mat.mtrl-sci', 'astro-ph', 'math.NT', 'hep-th', 'hep-ex', 'math.NA', 'nlin.PS', 'math.RA', 'cond-mat.str-el', 'physics.pop-ph', 'nucl-th', 'math.FA', 'cs.DS', 'math.DS', 'physics.soc-ph', 'math.AG', 'math.OA', 'math.PR', 'math.DG', 'physics.optics', 'math.GR', 'nlin.SI', 'math.SG', 'physics.data-an', 'cs.CC', 'math.GT', 'quant-ph', 'cond-mat.other', 'math.CV', 'math.AP', 'cond-mat.supr-con', 'math.RT', 'cond-mat.stat-mech', 'q-bio.OT', 'physics.plasm-ph', 'nlin.CG', 'nucl-ex', 'cond-mat.soft', 'physics.comp-ph', 'math.MG', 'math.QA', 'physics.bio-ph', 'physics.chem-ph', 'math.AT', 'physics.geo-ph', 'q-bio.BM', 'math.OC', 'cs.CR', 'physics.class-ph', 'q-bio.PE', 'q-bio.NC', 'physics.atom-ph', 'math.GM', 'hep-lat', 'math.CA', 'physics.atm-clus', 'cs.PF', 'physics.acc-ph', 'math.SP', 'nlin.CD', 'physics.hist-ph', 'physics.flu-dyn', 'cond-mat.dis-nn', 'cs.CV', 'cs.LG', 'cs.SE', 'physics.ed-ph', 'physics.ins-det', 'cs.PL', 'q-bio.CB', 'cs.AI', 'math.LO', 'cs.LO', 'stat.AP', 'nlin.AO', 'cs.DC', 'cs.DM', 'cs.NI', 'cs.OH', 'q-bio.GN', 'q-bio.MN', 'math.KT', 'math.AC', 'physics.med-ph', 'cs.HC', 'cs.NE', 'physics.ao-ph', 'math.HO', 'q-bio.QM', 'cs.MS', 'physics.space-ph', 'cs.DB', 'cs.CL', 'math.CT', 'cs.CE', 'cs.GT', 'cs.CY', 'cs.CG', 'stat.ME', 'cs.RO', 'cs.GL', 'cs.MA', 'math.GN', 'cs.IR', 'stat.ML', 'cs.DL', 'cs.SC', 'q-bio.SC', 'stat.CO', 'cs.NA', 'cs.AR', 'cs.OS', 'q-bio.TO', 'cs.GR', 'cs.MM', 'cs.SD', 'cond-mat.quant-gas', 'q-fin.GN', 'q-fin.ST', 'q-fin.PM', 'q-fin.PR', 'q-fin.CP', 'q-fin.RM', 'astro-ph.HE', 'astro-ph.SR', 'astro-ph.GA', 'astro-ph.CO', 'astro-ph.IM', 'astro-ph.EP', 'q-fin.TR', 'cs.FL', 'stat.OT', 'cs.SY', 'cs.SI', 'cs.ET', 'eess.SP', 'q-fin.EC', 'q-fin.MF', 'physics.app-ph', 'econ.TH', 'eess.IV', 'econ.EM', 'eess.AS', 'cond-mat']\n",
      "\n",
      "Top 20 categories by frequency:\n",
      "astro-ph: 86911\n",
      "hep-ph: 78579\n",
      "quant-ph: 62941\n",
      "hep-th: 56826\n",
      "cs.CV: 42747\n",
      "cond-mat.mtrl-sci: 35907\n",
      "cond-mat.mes-hall: 33087\n",
      "math.AP: 30351\n",
      "gr-qc: 28549\n",
      "astro-ph.GA: 27115\n",
      "math.CO: 26418\n",
      "astro-ph.SR: 25654\n",
      "cond-mat.str-el: 24923\n",
      "math.PR: 21938\n",
      "astro-ph.HE: 20833\n",
      "astro-ph.CO: 20707\n",
      "math.NT: 19918\n",
      "cond-mat.stat-mech: 18757\n",
      "nucl-th: 18733\n",
      "math.AG: 18712\n",
      "\n",
      "Total valid categories: 149\n",
      "\n",
      "Final dataset size: 100000\n",
      "Category distribution in the sample:\n",
      "astro-ph    7184\n",
      "hep-ph      6495\n",
      "quant-ph    5203\n",
      "hep-th      4697\n",
      "cs.CV       3533\n",
      "            ... \n",
      "cs.OS         22\n",
      "nlin.CG       18\n",
      "q-bio.SC      17\n",
      "q-fin.EC      17\n",
      "cs.GL          6\n",
      "Name: categories, Length: 149, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define the columns to extract\n",
    "cols = ['id', 'title', 'abstract', 'categories', 'authors', 'comments', 'update_date']\n",
    "\n",
    "# Initialize a Counter to store unique categories\n",
    "category_counter = Counter()\n",
    "\n",
    "# Load data and extract relevant fields + count categories\n",
    "data = []\n",
    "with open(file_name, encoding='latin-1') as f:\n",
    "    for line in f:\n",
    "        doc = json.loads(line)\n",
    "        categories = doc.get('categories', '').strip()\n",
    "        if categories and ' ' not in categories:  # Include only rows with a single category\n",
    "            category_counter.update([categories])\n",
    "            data.append([\n",
    "                doc.get('id'),\n",
    "                doc.get('title', ''),\n",
    "                doc.get('abstract', ''),\n",
    "                categories,\n",
    "                doc.get('authors', ''),\n",
    "                doc.get('comments', ''),\n",
    "                doc.get('update_date', '')\n",
    "            ])\n",
    "\n",
    "# Print unique categories\n",
    "unique_categories = list(category_counter.keys())\n",
    "print(f\"Total unique categories: {len(unique_categories)}\")\n",
    "print(\"Unique categories:\")\n",
    "print(unique_categories)\n",
    "\n",
    "# Optionally, print the top 20 most common categories with their counts\n",
    "print(\"\\nTop 20 categories by frequency:\")\n",
    "for category, count in category_counter.most_common(20):\n",
    "    print(f\"{category}: {count}\")\n",
    "\n",
    "# Convert data to DataFrame\n",
    "df = pd.DataFrame(data, columns=cols)\n",
    "\n",
    "# Clean the DataFrame\n",
    "df['abstract'] = df['abstract'].str.strip().str.lower()\n",
    "df['title'] = df['title'].str.strip().str.lower()\n",
    "df['categories'] = df['categories'].str.strip()\n",
    "df['authors'] = df['authors'].str.strip()\n",
    "df['comments'] = df['comments'].str.strip()\n",
    "df['update_date'] = pd.to_datetime(df['update_date'], errors='coerce')\n",
    "\n",
    "# Drop rows with missing abstracts or titles\n",
    "df = df.dropna(subset=['abstract', 'title'])\n",
    "\n",
    "# Filter out categories with fewer than 10 samples\n",
    "category_counts = df['categories'].value_counts()\n",
    "valid_categories = category_counts[category_counts >= 50].index\n",
    "print(f\"\\nTotal valid categories: {len(valid_categories)}\")\n",
    "\n",
    "# Filter the DataFrame to include only valid categories\n",
    "df_filtered = df[df['categories'].isin(valid_categories)]\n",
    "\n",
    "# Stratified sampling based on categories\n",
    "if len(df_filtered) < 100000:\n",
    "    raise ValueError(f\"Not enough data to sample 100,000 rows. Available: {len(df_filtered)}\")\n",
    "\n",
    "stratified_sample, _ = train_test_split(\n",
    "    df_filtered,\n",
    "    train_size=100000,\n",
    "    stratify=df_filtered['categories'],\n",
    "    random_state=62\n",
    ")\n",
    "\n",
    "# Reset index\n",
    "stratified_sample = stratified_sample.reset_index(drop=True)\n",
    "\n",
    "# Save the final sample to a CSV file\n",
    "stratified_sample.to_csv('stratified_sample.csv', index=False)\n",
    "\n",
    "# Display summary\n",
    "print(f\"\\nFinal dataset size: {len(stratified_sample)}\")\n",
    "print(\"Category distribution in the sample:\")\n",
    "print(stratified_sample['categories'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering the sample further to exclude categories with unique counts less than 20 to maintain a stratified distribution throughout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aQ-HEBCENV8k",
    "outputId": "15bd91d6-e3ed-4bbb-9b37-527cc898c846"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 100000\n",
      "Filtered dataset size: 99942\n",
      "Categories with fewer than 20 records have been removed.\n",
      "Updated category distribution:\n",
      "astro-ph    7184\n",
      "hep-ph      6495\n",
      "quant-ph    5203\n",
      "hep-th      4697\n",
      "cs.CV       3533\n",
      "            ... \n",
      "q-fin.PM      27\n",
      "q-fin.TR      27\n",
      "cs.MS         26\n",
      "q-bio.CB      26\n",
      "cs.OS         22\n",
      "Name: categories, Length: 145, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load your DataFrame\n",
    "df = pd.read_csv('stratified_sample.csv')\n",
    "\n",
    "# Get category counts\n",
    "category_counts = df['categories'].value_counts()\n",
    "\n",
    "# Identify categories with 20 or more occurrences\n",
    "valid_categories = category_counts[category_counts >= 20].index\n",
    "\n",
    "# Filter DataFrame to keep only rows with valid categories\n",
    "df_filtered = df[df['categories'].isin(valid_categories)]\n",
    "\n",
    "# Display the number of rows before and after filtering\n",
    "print(f\"Original dataset size: {len(df)}\")\n",
    "print(f\"Filtered dataset size: {len(df_filtered)}\")\n",
    "\n",
    "# Save the filtered DataFrame to a new CSV file\n",
    "df_filtered.to_csv('filtered_stratified_sample.csv', index=False)\n",
    "\n",
    "# Display summary\n",
    "print(\"Categories with fewer than 20 records have been removed.\")\n",
    "print(\"Updated category distribution:\")\n",
    "print(df_filtered['categories'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the sample into Train(70K), Validation(15K), Test(15K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>categories</th>\n",
       "      <th>authors</th>\n",
       "      <th>comments</th>\n",
       "      <th>update_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>astro-ph/0607362</td>\n",
       "      <td>the virial balance of clumps and cores in molecular clouds</td>\n",
       "      <td>we study the instantaneous virial balance of clumps and cores (ccs) in 3d\\nsimulations of driven, mhd, isothermal molecular clouds (mcs). the models\\nrepresent a range of magnetic field strengths in mcs from subcritical to\\nnon-magnetic regimes. we identify ccs at different density thresholds, and for\\neach object, we calculate all the terms that enter the eulerian form of the\\nvirial theorem (evt). a cc is considered gravitationally bound when the\\ngravitational term in the evt is larger than the amount for the system to be\\nvirialized, which is more stringent than the condition that it be large enough\\nto make the total volume energy negative. we also calculate, quantities\\ncommonly used in the observations to indicate the state of gravitational\\nboundedness of ccs such as the jeans number j_c, the mass-to magnetic flux\\nratio mu_c, and the virial parameter alpha_vir. our results show that: a) ccs\\nare dynamical out-of-equilibrium structures. b) the surface energies are of the\\nsame order than their volume counterparts c) ccs are either in the process of\\nbeing compressed or dispersed by the velocity field. yet, not all ccs that have\\na compressive net kinetic energy are gravitationally bound. d) there is no\\n1-to-1 correspondence between the state of gravitational boundedness of a cc as\\ndescribed by the virial analysis or as implied by the classical indicators. in\\ngeneral, in the virial analysis, we observe that only the inner regions of the\\nobjects are gravitationally bound, whereas j_c, alpha_vir, and mu_c estimates\\ntend to show that they are more gravitationally bound at the lowest threshold\\nlevels and more magnetically supercritical. g) we observe, in the non-magnetic\\nsimulation, the existence of a bound core with structural and dynamical\\nproperties that resemble those of the bok globule barnard 68 (b68).</td>\n",
       "      <td>astro-ph</td>\n",
       "      <td>Sami Dib (1,2), Jongsoo Kim (2), Enrique Vazquez-Semadeni (1), Andreas\\n  Burkert (3), Mohsen Shadmehri (4,5) ((1) CRyA-UNAM, (2) KASI, (3) USM, (4)\\n  DCU, (5) Ferdowsi Univ.)</td>\n",
       "      <td>Accepted to ApJ. Discussion substantially enlarged, a few corrections\\n  and additional figures. Main conclusions unchanged</td>\n",
       "      <td>2011-02-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2108.03495</td>\n",
       "      <td>game theory and machine learning in uavs-assisted wireless communication\\n  networks: a survey</td>\n",
       "      <td>in recent years, unmanned aerial vehicles (uavs) have been used in fields\\nsuch as architecture, business delivery, military and civilian theaters, and\\nmany others. with increased applications comes the increased demand for\\nadvanced algorithms for resource allocation and energy management. as is well\\nknown, game theory and machine learning are two powerful tools already widely\\nused in the wireless communication field and there are numerous surveys of game\\ntheory and machine learning usage in wireless communication. existing surveys\\nhowever focus either on game theory or machine learning and due to this fact,\\nthe current article surveys both game-theoretic and machine learning algorithms\\nfor use by uavs in wireless communication networks (u-wcns). we also discuss\\nhow to combine game theory and machine learning for solving problems in u-wcns\\nand identify several future research directions.</td>\n",
       "      <td>cs.MA</td>\n",
       "      <td>M. Zhou, Y. Guan, M. Hayajneh, K. Niu, and C. Abdallah</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-08-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1607.08427</td>\n",
       "      <td>gyroscope precession along bound equatorial plane orbits around a kerr\\n  black hole</td>\n",
       "      <td>the precession of a test gyroscope along stable bound equatorial plane orbits\\naround a kerr black hole is analyzed and the precession angular velocity of the\\ngyro's parallel transported spin vector and the increment in precession angle\\nafter one orbital period is evaluated. the parallel transported marck frame\\nwhich enters this discussion is shown to have an elegant geometrical\\nexplanation in terms of the electric and magnetic parts of the killing-yano\\n2-form and a wigner rotation effect.</td>\n",
       "      <td>gr-qc</td>\n",
       "      <td>Donato Bini, Andrea Geralico, Robert T. Jantzen</td>\n",
       "      <td>16 pages; revtex macros; 3 eps figures</td>\n",
       "      <td>2016-09-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1405.0627</td>\n",
       "      <td>a stochastic approach for quantifying immigrant integration: the spanish\\n  test case</td>\n",
       "      <td>we apply stochastic process theory to the analysis of immigrant integration.\\nusing a unique and detailed data set from spain, we study the relationship\\nbetween local immigrant density and two social and two economic immigration\\nquantifiers for the period 1999-2010. as opposed to the classic time-series\\napproach, by letting immigrant density play the role of \"time\", and the\\nquantifier the role of \"space\" it become possible to analyze the behavior of\\nthe quantifiers by means of continuous time random walks. two classes of\\nresults are obtained. first we show that social integration quantifiers evolve\\nfollowing pure diffusion law, while the evolution of economic quantifiers\\nexhibit ballistic dynamics. second we make predictions of best and worst case\\nscenarios taking into account large local fluctuations. our stochastic process\\napproach to integration lends itself to interesting forecasting scenarios\\nwhich, in the hands of policy makers, have the potential to improve political\\nresponses to integration problems. for instance, estimating the standard\\nfirst-passage time and maximum-span walk reveals local differences in\\nintegration performance for different immigration scenarios. thus, by\\nrecognizing the importance of local fluctuations around national means, this\\nresearch constitutes an important tool to assess the impact of immigration\\nphenomena on municipal budgets and to set up solid multi-ethnic plans at the\\nmunicipal level as immigration pressure build.</td>\n",
       "      <td>physics.soc-ph</td>\n",
       "      <td>Elena Agliari, Adriano Barra, Pierluigi Contucci, Rickard Sandell,\\n  Cecilia Vernia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-02-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2201.08949</td>\n",
       "      <td>temporal aggregation for adaptive rgbt tracking</td>\n",
       "      <td>visual object tracking with rgb and thermal infrared (tir) spectra available,\\nshorted in rgbt tracking, is a novel and challenging research topic which draws\\nincreasing attention nowadays. in this paper, we propose an rgbt tracker which\\ntakes spatio-temporal clues into account for robust appearance model learning,\\nand simultaneously, constructs an adaptive fusion sub-network for cross-modal\\ninteractions. unlike most existing rgbt trackers that implement object tracking\\ntasks with only spatial information included, temporal information is further\\nconsidered in this method. specifically, different from traditional siamese\\ntrackers, which only obtain one search image during the process of picking up\\ntemplate-search image pairs, an extra search sample adjacent to the original\\none is selected to predict the temporal transformation, resulting in improved\\nrobustness of tracking performance.as for multi-modal tracking, constrained to\\nthe limited rgbt datasets, the adaptive fusion sub-network is appended to our\\nmethod at the decision level to reflect the complementary characteristics\\ncontained in two modalities. to design a thermal infrared assisted rgb tracker,\\nthe outputs of the classification head from the tir modality are taken into\\nconsideration before the residual connection from the rgb modality. extensive\\nexperimental results on three challenging datasets, i.e. vot-rgbt2019, gtot and\\nrgbt210, verify the effectiveness of our method. code will be shared at\\n\\textcolor{blue}{\\emph{https://github.com/zhangyong-tang/taat}}.</td>\n",
       "      <td>cs.CV</td>\n",
       "      <td>Zhangyong Tang, Tianyang Xu, and Xiao-Jun Wu</td>\n",
       "      <td>12 pages, 10 figures</td>\n",
       "      <td>2022-02-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  \\\n",
       "0  astro-ph/0607362   \n",
       "1        2108.03495   \n",
       "2        1607.08427   \n",
       "3         1405.0627   \n",
       "4        2201.08949   \n",
       "\n",
       "                                                                                            title  \\\n",
       "0                                      the virial balance of clumps and cores in molecular clouds   \n",
       "1  game theory and machine learning in uavs-assisted wireless communication\\n  networks: a survey   \n",
       "2            gyroscope precession along bound equatorial plane orbits around a kerr\\n  black hole   \n",
       "3           a stochastic approach for quantifying immigrant integration: the spanish\\n  test case   \n",
       "4                                                 temporal aggregation for adaptive rgbt tracking   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     abstract  \\\n",
       "0  we study the instantaneous virial balance of clumps and cores (ccs) in 3d\\nsimulations of driven, mhd, isothermal molecular clouds (mcs). the models\\nrepresent a range of magnetic field strengths in mcs from subcritical to\\nnon-magnetic regimes. we identify ccs at different density thresholds, and for\\neach object, we calculate all the terms that enter the eulerian form of the\\nvirial theorem (evt). a cc is considered gravitationally bound when the\\ngravitational term in the evt is larger than the amount for the system to be\\nvirialized, which is more stringent than the condition that it be large enough\\nto make the total volume energy negative. we also calculate, quantities\\ncommonly used in the observations to indicate the state of gravitational\\nboundedness of ccs such as the jeans number j_c, the mass-to magnetic flux\\nratio mu_c, and the virial parameter alpha_vir. our results show that: a) ccs\\nare dynamical out-of-equilibrium structures. b) the surface energies are of the\\nsame order than their volume counterparts c) ccs are either in the process of\\nbeing compressed or dispersed by the velocity field. yet, not all ccs that have\\na compressive net kinetic energy are gravitationally bound. d) there is no\\n1-to-1 correspondence between the state of gravitational boundedness of a cc as\\ndescribed by the virial analysis or as implied by the classical indicators. in\\ngeneral, in the virial analysis, we observe that only the inner regions of the\\nobjects are gravitationally bound, whereas j_c, alpha_vir, and mu_c estimates\\ntend to show that they are more gravitationally bound at the lowest threshold\\nlevels and more magnetically supercritical. g) we observe, in the non-magnetic\\nsimulation, the existence of a bound core with structural and dynamical\\nproperties that resemble those of the bok globule barnard 68 (b68).   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              in recent years, unmanned aerial vehicles (uavs) have been used in fields\\nsuch as architecture, business delivery, military and civilian theaters, and\\nmany others. with increased applications comes the increased demand for\\nadvanced algorithms for resource allocation and energy management. as is well\\nknown, game theory and machine learning are two powerful tools already widely\\nused in the wireless communication field and there are numerous surveys of game\\ntheory and machine learning usage in wireless communication. existing surveys\\nhowever focus either on game theory or machine learning and due to this fact,\\nthe current article surveys both game-theoretic and machine learning algorithms\\nfor use by uavs in wireless communication networks (u-wcns). we also discuss\\nhow to combine game theory and machine learning for solving problems in u-wcns\\nand identify several future research directions.   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         the precession of a test gyroscope along stable bound equatorial plane orbits\\naround a kerr black hole is analyzed and the precession angular velocity of the\\ngyro's parallel transported spin vector and the increment in precession angle\\nafter one orbital period is evaluated. the parallel transported marck frame\\nwhich enters this discussion is shown to have an elegant geometrical\\nexplanation in terms of the electric and magnetic parts of the killing-yano\\n2-form and a wigner rotation effect.   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                     we apply stochastic process theory to the analysis of immigrant integration.\\nusing a unique and detailed data set from spain, we study the relationship\\nbetween local immigrant density and two social and two economic immigration\\nquantifiers for the period 1999-2010. as opposed to the classic time-series\\napproach, by letting immigrant density play the role of \"time\", and the\\nquantifier the role of \"space\" it become possible to analyze the behavior of\\nthe quantifiers by means of continuous time random walks. two classes of\\nresults are obtained. first we show that social integration quantifiers evolve\\nfollowing pure diffusion law, while the evolution of economic quantifiers\\nexhibit ballistic dynamics. second we make predictions of best and worst case\\nscenarios taking into account large local fluctuations. our stochastic process\\napproach to integration lends itself to interesting forecasting scenarios\\nwhich, in the hands of policy makers, have the potential to improve political\\nresponses to integration problems. for instance, estimating the standard\\nfirst-passage time and maximum-span walk reveals local differences in\\nintegration performance for different immigration scenarios. thus, by\\nrecognizing the importance of local fluctuations around national means, this\\nresearch constitutes an important tool to assess the impact of immigration\\nphenomena on municipal budgets and to set up solid multi-ethnic plans at the\\nmunicipal level as immigration pressure build.   \n",
       "4                                                                                                                                                                                                                                                                                                   visual object tracking with rgb and thermal infrared (tir) spectra available,\\nshorted in rgbt tracking, is a novel and challenging research topic which draws\\nincreasing attention nowadays. in this paper, we propose an rgbt tracker which\\ntakes spatio-temporal clues into account for robust appearance model learning,\\nand simultaneously, constructs an adaptive fusion sub-network for cross-modal\\ninteractions. unlike most existing rgbt trackers that implement object tracking\\ntasks with only spatial information included, temporal information is further\\nconsidered in this method. specifically, different from traditional siamese\\ntrackers, which only obtain one search image during the process of picking up\\ntemplate-search image pairs, an extra search sample adjacent to the original\\none is selected to predict the temporal transformation, resulting in improved\\nrobustness of tracking performance.as for multi-modal tracking, constrained to\\nthe limited rgbt datasets, the adaptive fusion sub-network is appended to our\\nmethod at the decision level to reflect the complementary characteristics\\ncontained in two modalities. to design a thermal infrared assisted rgb tracker,\\nthe outputs of the classification head from the tir modality are taken into\\nconsideration before the residual connection from the rgb modality. extensive\\nexperimental results on three challenging datasets, i.e. vot-rgbt2019, gtot and\\nrgbt210, verify the effectiveness of our method. code will be shared at\\n\\textcolor{blue}{\\emph{https://github.com/zhangyong-tang/taat}}.   \n",
       "\n",
       "       categories  \\\n",
       "0        astro-ph   \n",
       "1           cs.MA   \n",
       "2           gr-qc   \n",
       "3  physics.soc-ph   \n",
       "4           cs.CV   \n",
       "\n",
       "                                                                                                                                                                            authors  \\\n",
       "0  Sami Dib (1,2), Jongsoo Kim (2), Enrique Vazquez-Semadeni (1), Andreas\\n  Burkert (3), Mohsen Shadmehri (4,5) ((1) CRyA-UNAM, (2) KASI, (3) USM, (4)\\n  DCU, (5) Ferdowsi Univ.)   \n",
       "1                                                                                                                            M. Zhou, Y. Guan, M. Hayajneh, K. Niu, and C. Abdallah   \n",
       "2                                                                                                                                   Donato Bini, Andrea Geralico, Robert T. Jantzen   \n",
       "3                                                                                              Elena Agliari, Adriano Barra, Pierluigi Contucci, Rickard Sandell,\\n  Cecilia Vernia   \n",
       "4                                                                                                                                      Zhangyong Tang, Tianyang Xu, and Xiao-Jun Wu   \n",
       "\n",
       "                                                                                                                      comments  \\\n",
       "0  Accepted to ApJ. Discussion substantially enlarged, a few corrections\\n  and additional figures. Main conclusions unchanged   \n",
       "1                                                                                                                          NaN   \n",
       "2                                                                                       16 pages; revtex macros; 3 eps figures   \n",
       "3                                                                                                                          NaN   \n",
       "4                                                                                                         12 pages, 10 figures   \n",
       "\n",
       "  update_date  \n",
       "0  2011-02-11  \n",
       "1  2021-08-10  \n",
       "2  2016-09-28  \n",
       "3  2016-02-02  \n",
       "4  2022-02-01  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ePSuA3gr9kNH",
    "outputId": "89a9eb1b-f1c1-4921-937b-97a031eb7053"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 70000\n",
      "Validation set size: 14971\n",
      "Test set size: 14971\n"
     ]
    }
   ],
   "source": [
    "# Load the stratified sample\n",
    "df = df_filtered\n",
    "\n",
    "# Split into train (70k) and remaining (30k)\n",
    "train_df, remaining_df = train_test_split(\n",
    "    df,\n",
    "    train_size=70000,\n",
    "    stratify=df['categories'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Split remaining into validation (15k) and test (15k)\n",
    "val_df, test_df = train_test_split(\n",
    "    remaining_df,\n",
    "    test_size=0.5,\n",
    "    stratify=remaining_df['categories'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Save the splits to CSV files\n",
    "train_df.to_csv('train_df.csv', index=False)\n",
    "val_df.to_csv('val_df.csv', index=False)\n",
    "test_df.to_csv('test_df.csv', index=False)\n",
    "\n",
    "# Display summary\n",
    "print(f\"Train set size: {len(train_df)}\")\n",
    "print(f\"Validation set size: {len(val_df)}\")\n",
    "print(f\"Test set size: {len(test_df)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing data by performing necessary cleaning operations (Lowercasing, Lemmatizing, Removing punctuations, whitespace, special characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nQYWqgY4-Umi",
    "outputId": "c7626815-7f07-4166-aa37-0a2f76537c0b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\prern\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\prern\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\prern\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id  \\\n",
      "0  1606.03119   \n",
      "1   1306.5681   \n",
      "2   1208.4287   \n",
      "3   1006.0121   \n",
      "4  2111.05140   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  enhanced_text  \n",
      "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Title: derivation centroid four dimensional associative algebra [SEP] Authors: ao abdulkareem fiidow rakhimov [SEP] Categories: mathra [SEP] Abstract: paper focus derivation centroid four dimensional associative algebra using existing classification result low dimensional associative algebra describe derivation centroid four dimensional associative algebra also identify algebra belong characteristically nilpotent class among algebra four dimensional associative algebra [SEP] Comments: 20 page 2 table accepted international journal pure applied mathematics [SEP] Updated on: 2017-02-21  \n",
      "1                                                                                                                                                                         Title: coupledcluster study infinite nuclear matter [SEP] Authors: g baardsen ekstrom g hagen hjorthjensen [SEP] Categories: nuclth [SEP] Abstract: aim work develop relevant formalism performing coupledcluster cc calculation nuclear matter neutron star matter including thereby important correlation infinite order interaction testing modern nuclear force based chiral effective field theory formalism includes exact treatment socalled pauli operator partial wave expansion equation state nuclear neutron matter calculation done using coupled particleparticle holehole ladder approximation coupled ladder equation derived approximation cc theory leaving particlehole nonlinear diagram cc double amplitude equation study first step toward cc calculation nuclear neutron matter present result symmetric nuclear matter pure neutron matter employing stateoftheart nucleonnucleon interaction based chiral effective field theory employ also newly optimized chiral interaction ekstrom et al phys rev lett 110 192502 2013 study infinite nuclear matter ladder approximation method corresponding result compared conventional bruecknerhartreefock theory [SEP] Comments: 18 page 14 figure [SEP] Updated on: 2013-11-18  \n",
      "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Title: regularity uniqueness heat ow biharmonic map [SEP] Authors: jay hineman tao huang changyou wang [SEP] Categories: mathap [SEP] Abstract: paper first establish regularity heat flow biharmonic map unit sphere slsubsetmathbb rl1 smallness condition renormalized total energy class solution heat flow biharmonic map prove property uniqueness convexity hessian energy unique limit time infinity establish regularity uniqueness class weak solution u heat flow biharmonic map compact riemannian manifold n without boundary nabla2 uin lqtlpx pn2 q2 satisfying 113 [SEP] Comments: two error proof proposition 22 fixed consequence range power p main theorem paper required p32 [SEP] Updated on: 2012-09-25  \n",
      "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Title: smallscale behaviour deterministic reaction model [SEP] Authors: paolo politi daniel benavraham [SEP] Categories: condmatstatmech [SEP] Abstract: recent paper published journal j phys math theor 42 2009 495004 studied onedimensional particle system nearest particle attract force inversely proportional power alpha distance coalesce upon encounter numerics yielded distribution function hz gap neighbouring particle hzzbetaalpha small z betaalphaalpha prove analytically strict limit zto 0 betaalpha alpha0 corresponding meanfield result compute length scale meanfield break generally limit correlation negligible similar reaction model attractive force diverge vanishing distance actual meaning measured exponent betaalpha remains open question [SEP] Comments: six page section 2 rewritten accepted publication journal physic mathematical theoretical [SEP] Updated on: 2010-09-07  \n",
      "4  Title: twodimensional phonon polaritons multilayers hexagonal boron nitride macroscopic phonon model [SEP] Authors: jianzhong zhang [SEP] Categories: condmatmeshall [SEP] Abstract: phonon polaritons phps freestanding supported multilayers muls hexagonal boron nitride hbn systematically studied using macroscopic opticalphonon model php property confinement group velocity propagation quality factor pqf wavelength scaling studied owing nonlocal highfrequency screening upper frequency limit making twodimensional 2d phps frequency band also maximum pqf occurs near centre frequency substrate dielectric response included accurately calculate php property simple electrostatic approximation esa proper treatment php frequency omega omega0 eg omega103omega0 30layers omega0 gamma point optical phonon frequency fails describe php property near omega0 effect retardation included accurate description php wavelength versus layer thickness near omega0 deviate significantly linear scaling law given esa due strong phononphoton coupling calculated php dispersion pqf scaling compared experimental data number spectroscopic study good agreement obtained frequency incident light near centre frequency maximize pqf php wavelength confinement propagation length engineered varying mul thickness dielectric environment [SEP] Comments: 18 page 9 figure [SEP] Updated on: 2022-03-14  \n",
      "Enhanced text field created and saved successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Download NLTK resources if not already downloaded\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# Load the stratified sample dataset\n",
    "df = pd.read_csv('train_df.csv')\n",
    "\n",
    "# Initialize stopwords and lemmatizer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    if pd.isnull(text):\n",
    "        return \"\"\n",
    "    # Lowercasing\n",
    "    text = text.lower()\n",
    "    # Remove special characters and punctuation\n",
    "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
    "    # Remove extra whitespace and newlines\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    # Tokenize and remove stopwords, then lemmatize\n",
    "    tokens = text.split()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply cleaning to relevant fields\n",
    "df['cleaned_title'] = df['title'].apply(clean_text)\n",
    "df['cleaned_authors'] = df['authors'].apply(clean_text)\n",
    "df['cleaned_categories'] = df['categories'].apply(clean_text)\n",
    "df['cleaned_abstract'] = df['abstract'].apply(clean_text)\n",
    "df['cleaned_comments'] = df['comments'].apply(clean_text)\n",
    "\n",
    "# Create the enhanced text field and remove newlines\n",
    "df['enhanced_text'] = df.apply(lambda row: f\"\"\"\n",
    "Title: {row['cleaned_title']} [SEP]\n",
    "Authors: {row['cleaned_authors']} [SEP]\n",
    "Categories: {row['cleaned_categories']} [SEP]\n",
    "Abstract: {row['cleaned_abstract']} [SEP]\n",
    "Comments: {row['cleaned_comments']} [SEP]\n",
    "Updated on: {row['update_date']}\n",
    "\"\"\".replace('\\n', ' ').strip(), axis=1)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Display the first few rows to verify the enhanced text field\n",
    "print(df[['id', 'enhanced_text']].head())\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "df.to_csv('enhanced_stratified_sample_train.csv', index=False)\n",
    "\n",
    "print(\"Enhanced text field created and saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>categories</th>\n",
       "      <th>authors</th>\n",
       "      <th>comments</th>\n",
       "      <th>update_date</th>\n",
       "      <th>cleaned_title</th>\n",
       "      <th>cleaned_authors</th>\n",
       "      <th>cleaned_categories</th>\n",
       "      <th>cleaned_abstract</th>\n",
       "      <th>cleaned_comments</th>\n",
       "      <th>enhanced_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1606.03119</td>\n",
       "      <td>derivations and centroids of four dimensional associative algebras</td>\n",
       "      <td>in this paper, we focus on derivations and centroids of four dimensional\\nassociative algebras. using an existing classification result of low\\ndimensional associative algebras, we describe the derivations and centroids of\\nfour dimensional associative algebras. we also identify algebra(s) that belong\\nto the characteristically nilpotent class among the algebras of four\\ndimensional associative algebras.</td>\n",
       "      <td>math.RA</td>\n",
       "      <td>A.O. Abdulkareem, M.A. Fiidow and I.S. Rakhimov</td>\n",
       "      <td>20 pages, 2 tables, Accepted in International Journal of Pure and\\n  Applied Mathematics</td>\n",
       "      <td>2017-02-21</td>\n",
       "      <td>derivation centroid four dimensional associative algebra</td>\n",
       "      <td>ao abdulkareem fiidow rakhimov</td>\n",
       "      <td>mathra</td>\n",
       "      <td>paper focus derivation centroid four dimensional associative algebra using existing classification result low dimensional associative algebra describe derivation centroid four dimensional associative algebra also identify algebra belong characteristically nilpotent class among algebra four dimensional associative algebra</td>\n",
       "      <td>20 page 2 table accepted international journal pure applied mathematics</td>\n",
       "      <td>Title: derivation centroid four dimensional associative algebra [SEP] Authors: ao abdulkareem fiidow rakhimov [SEP] Categories: mathra [SEP] Abstract: paper focus derivation centroid four dimensional associative algebra using existing classification result low dimensional associative algebra describe derivation centroid four dimensional associative algebra also identify algebra belong characteristically nilpotent class among algebra four dimensional associative algebra [SEP] Comments: 20 page 2 table accepted international journal pure applied mathematics [SEP] Updated on: 2017-02-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1306.5681</td>\n",
       "      <td>coupled-cluster studies of infinite nuclear matter</td>\n",
       "      <td>the aim of this work is to develop the relevant formalism for performing\\ncoupled-cluster (cc) calculations in nuclear matter and neutron star matter,\\nincluding thereby important correlations to infinite order in the interaction\\nand testing modern nuclear forces based on chiral effective field theory. our\\nformalism includes the exact treatment of the so-called pauli operator in a\\npartial wave expansion of the equation of state. nuclear and neutron matter\\ncalculations are done using a coupled particle-particle and hole-hole ladder\\napproximation. the coupled ladder equations are derived as an approximation of\\ncc theory, leaving out particle-hole and non-linear diagrams from the cc\\ndoubles amplitude equation. this study is a first step toward cc calculations\\nfor nuclear and neutron matter. we present results for both symmetric nuclear\\nmatter and pure neutron matter employing state-of-the-art nucleon-nucleon\\ninteractions based on chiral effective field theory. we employ also the newly\\noptimized chiral interaction [a. ekstr\\\"om et al., phys. rev. lett. 110, 192502\\n(2013)] to study infinite nuclear matter. the ladder approximation method and\\ncorresponding results are compared with conventional brueckner-hartree-fock\\ntheory.</td>\n",
       "      <td>nucl-th</td>\n",
       "      <td>G. Baardsen, A. Ekstr\\\"om, G. Hagen and M. Hjorth-Jensen</td>\n",
       "      <td>18 pages, 14 figures</td>\n",
       "      <td>2013-11-18</td>\n",
       "      <td>coupledcluster study infinite nuclear matter</td>\n",
       "      <td>g baardsen ekstrom g hagen hjorthjensen</td>\n",
       "      <td>nuclth</td>\n",
       "      <td>aim work develop relevant formalism performing coupledcluster cc calculation nuclear matter neutron star matter including thereby important correlation infinite order interaction testing modern nuclear force based chiral effective field theory formalism includes exact treatment socalled pauli operator partial wave expansion equation state nuclear neutron matter calculation done using coupled particleparticle holehole ladder approximation coupled ladder equation derived approximation cc theory leaving particlehole nonlinear diagram cc double amplitude equation study first step toward cc calculation nuclear neutron matter present result symmetric nuclear matter pure neutron matter employing stateoftheart nucleonnucleon interaction based chiral effective field theory employ also newly optimized chiral interaction ekstrom et al phys rev lett 110 192502 2013 study infinite nuclear matter ladder approximation method corresponding result compared conventional bruecknerhartreefock theory</td>\n",
       "      <td>18 page 14 figure</td>\n",
       "      <td>Title: coupledcluster study infinite nuclear matter [SEP] Authors: g baardsen ekstrom g hagen hjorthjensen [SEP] Categories: nuclth [SEP] Abstract: aim work develop relevant formalism performing coupledcluster cc calculation nuclear matter neutron star matter including thereby important correlation infinite order interaction testing modern nuclear force based chiral effective field theory formalism includes exact treatment socalled pauli operator partial wave expansion equation state nuclear neutron matter calculation done using coupled particleparticle holehole ladder approximation coupled ladder equation derived approximation cc theory leaving particlehole nonlinear diagram cc double amplitude equation study first step toward cc calculation nuclear neutron matter present result symmetric nuclear matter pure neutron matter employing stateoftheart nucleonnucleon interaction based chiral effective field theory employ also newly optimized chiral interaction ekstrom et al phys rev lett 110 192502 2013 study infinite nuclear matter ladder approximation method corresponding result compared conventional bruecknerhartreefock theory [SEP] Comments: 18 page 14 figure [SEP] Updated on: 2013-11-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1208.4287</td>\n",
       "      <td>regularity and uniqueness of the heat ow of biharmonic maps</td>\n",
       "      <td>in this paper, we first establish regularity of the heat flow of biharmonic\\nmaps into the unit sphere $s^l\\subset\\mathbb r^{l+1}$ under a smallness\\ncondition of renormalized total energy. for the class of such solutions to the\\nheat flow of biharmonic maps, we prove the properties of uniqueness, convexity\\nof hessian energy, and unique limit at time infinity. we establish both\\nregularity and uniqueness for the class of weak solutions $u$ to the heat flow\\nof biharmonic maps into any compact riemannian manifold $n$ without boundary\\nsuch that $\\nabla^2 u\\in l^q_tl^p_x$ for some $p&gt;n/2$ and $q&gt;2$ satisfying\\n(1.13).</td>\n",
       "      <td>math.AP</td>\n",
       "      <td>Jay Hineman, Tao Huang, Changyou Wang</td>\n",
       "      <td>Two errors in the proof of proposition 2.2 have been fixed, as a\\n  consequence the range of the power $p$ through the main theorems of the paper\\n  is required to $p&gt;3/2$</td>\n",
       "      <td>2012-09-25</td>\n",
       "      <td>regularity uniqueness heat ow biharmonic map</td>\n",
       "      <td>jay hineman tao huang changyou wang</td>\n",
       "      <td>mathap</td>\n",
       "      <td>paper first establish regularity heat flow biharmonic map unit sphere slsubsetmathbb rl1 smallness condition renormalized total energy class solution heat flow biharmonic map prove property uniqueness convexity hessian energy unique limit time infinity establish regularity uniqueness class weak solution u heat flow biharmonic map compact riemannian manifold n without boundary nabla2 uin lqtlpx pn2 q2 satisfying 113</td>\n",
       "      <td>two error proof proposition 22 fixed consequence range power p main theorem paper required p32</td>\n",
       "      <td>Title: regularity uniqueness heat ow biharmonic map [SEP] Authors: jay hineman tao huang changyou wang [SEP] Categories: mathap [SEP] Abstract: paper first establish regularity heat flow biharmonic map unit sphere slsubsetmathbb rl1 smallness condition renormalized total energy class solution heat flow biharmonic map prove property uniqueness convexity hessian energy unique limit time infinity establish regularity uniqueness class weak solution u heat flow biharmonic map compact riemannian manifold n without boundary nabla2 uin lqtlpx pn2 q2 satisfying 113 [SEP] Comments: two error proof proposition 22 fixed consequence range power p main theorem paper required p32 [SEP] Updated on: 2012-09-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1006.0121</td>\n",
       "      <td>small-scale behaviour in deterministic reaction models</td>\n",
       "      <td>in a recent paper published in this journal [j. phys. a: math. theor. 42\\n(2009) 495004] we studied a one-dimensional particles system where nearest\\nparticles attract with a force inversely proportional to a power \\alpha of\\ntheir distance and coalesce upon encounter. numerics yielded a distribution\\nfunction h(z) for the gap between neighbouring particles, with\\nh(z)=z^{\\beta(\\alpha)} for small z and \\beta(\\alpha)&gt;\\alpha. we can now prove\\nanalytically that in the strict limit of z\\to 0, \\beta=\\alpha for \\alpha&gt;0,\\ncorresponding to the mean-field result, and we compute the length scale where\\nmean-field breaks down. more generally, in that same limit correlations are\\nnegligible for any similar reaction model where attractive forces diverge with\\nvanishing distance. the actual meaning of the measured exponent \\beta(\\alpha)\\nremains an open question.</td>\n",
       "      <td>cond-mat.stat-mech</td>\n",
       "      <td>Paolo Politi and Daniel ben-Avraham</td>\n",
       "      <td>Six pages. Section 2 has been rewritten. Accepted for publication in\\n  Journal of Physics A: Mathematical and Theoretical</td>\n",
       "      <td>2010-09-07</td>\n",
       "      <td>smallscale behaviour deterministic reaction model</td>\n",
       "      <td>paolo politi daniel benavraham</td>\n",
       "      <td>condmatstatmech</td>\n",
       "      <td>recent paper published journal j phys math theor 42 2009 495004 studied onedimensional particle system nearest particle attract force inversely proportional power alpha distance coalesce upon encounter numerics yielded distribution function hz gap neighbouring particle hzzbetaalpha small z betaalphaalpha prove analytically strict limit zto 0 betaalpha alpha0 corresponding meanfield result compute length scale meanfield break generally limit correlation negligible similar reaction model attractive force diverge vanishing distance actual meaning measured exponent betaalpha remains open question</td>\n",
       "      <td>six page section 2 rewritten accepted publication journal physic mathematical theoretical</td>\n",
       "      <td>Title: smallscale behaviour deterministic reaction model [SEP] Authors: paolo politi daniel benavraham [SEP] Categories: condmatstatmech [SEP] Abstract: recent paper published journal j phys math theor 42 2009 495004 studied onedimensional particle system nearest particle attract force inversely proportional power alpha distance coalesce upon encounter numerics yielded distribution function hz gap neighbouring particle hzzbetaalpha small z betaalphaalpha prove analytically strict limit zto 0 betaalpha alpha0 corresponding meanfield result compute length scale meanfield break generally limit correlation negligible similar reaction model attractive force diverge vanishing distance actual meaning measured exponent betaalpha remains open question [SEP] Comments: six page section 2 rewritten accepted publication journal physic mathematical theoretical [SEP] Updated on: 2010-09-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2111.05140</td>\n",
       "      <td>two-dimensional phonon polaritons in multilayers of hexagonal boron\\n  nitride from a macroscopic phonon model</td>\n",
       "      <td>phonon polaritons (phps) in freestanding and supported multilayers (muls) of\\nhexagonal boron nitride (hbn) are systematically studied using a macroscopic\\noptical-phonon model. the php properties such as confinement, group velocity,\\npropagation quality factor (pqf) and wavelength scaling are studied. owing to\\nthe nonlocal high-frequency screening, there is an upper frequency limit making\\nthe two-dimensional (2d) phps have a frequency band, and also a maximum pqf\\noccurs near the centre frequency. the substrate's dielectric response should be\\nincluded to accurately calculate the php properties. while the simple\\nelectrostatic approximation (esa) is a proper treatment for php frequencies\\n$\\omega$ above $\\omega_0$ (e.g. $\\omega&gt;1.03\\omega_0$ for the 30-layers;\\n$\\omega_0$ is the $\\gamma$ point optical phonon frequency), it fails to\\ndescribe the php properties near $\\omega_0$ and the effect of retardation\\nshould be included for an accurate description. the php wavelength versus the\\nlayer thickness near $\\omega_0$ deviates significantly from a linear scaling\\nlaw given by the esa due to strong phonon-photon coupling. the calculated php\\ndispersion, pqf and scaling are compared with experimental data of a number of\\nspectroscopic studies and good agreement is obtained. while the frequency of\\nincident light should be near the centre frequency to maximize the pqf, the php\\nwavelength, confinement and propagation length can be engineered by varying the\\nmul thickness and its dielectric environment.</td>\n",
       "      <td>cond-mat.mes-hall</td>\n",
       "      <td>Jian-zhong Zhang</td>\n",
       "      <td>18 pages and 9 figures</td>\n",
       "      <td>2022-03-14</td>\n",
       "      <td>twodimensional phonon polaritons multilayers hexagonal boron nitride macroscopic phonon model</td>\n",
       "      <td>jianzhong zhang</td>\n",
       "      <td>condmatmeshall</td>\n",
       "      <td>phonon polaritons phps freestanding supported multilayers muls hexagonal boron nitride hbn systematically studied using macroscopic opticalphonon model php property confinement group velocity propagation quality factor pqf wavelength scaling studied owing nonlocal highfrequency screening upper frequency limit making twodimensional 2d phps frequency band also maximum pqf occurs near centre frequency substrate dielectric response included accurately calculate php property simple electrostatic approximation esa proper treatment php frequency omega omega0 eg omega103omega0 30layers omega0 gamma point optical phonon frequency fails describe php property near omega0 effect retardation included accurate description php wavelength versus layer thickness near omega0 deviate significantly linear scaling law given esa due strong phononphoton coupling calculated php dispersion pqf scaling compared experimental data number spectroscopic study good agreement obtained frequency incident light near centre frequency maximize pqf php wavelength confinement propagation length engineered varying mul thickness dielectric environment</td>\n",
       "      <td>18 page 9 figure</td>\n",
       "      <td>Title: twodimensional phonon polaritons multilayers hexagonal boron nitride macroscopic phonon model [SEP] Authors: jianzhong zhang [SEP] Categories: condmatmeshall [SEP] Abstract: phonon polaritons phps freestanding supported multilayers muls hexagonal boron nitride hbn systematically studied using macroscopic opticalphonon model php property confinement group velocity propagation quality factor pqf wavelength scaling studied owing nonlocal highfrequency screening upper frequency limit making twodimensional 2d phps frequency band also maximum pqf occurs near centre frequency substrate dielectric response included accurately calculate php property simple electrostatic approximation esa proper treatment php frequency omega omega0 eg omega103omega0 30layers omega0 gamma point optical phonon frequency fails describe php property near omega0 effect retardation included accurate description php wavelength versus layer thickness near omega0 deviate significantly linear scaling law given esa due strong phononphoton coupling calculated php dispersion pqf scaling compared experimental data number spectroscopic study good agreement obtained frequency incident light near centre frequency maximize pqf php wavelength confinement propagation length engineered varying mul thickness dielectric environment [SEP] Comments: 18 page 9 figure [SEP] Updated on: 2022-03-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  \\\n",
       "0  1606.03119   \n",
       "1   1306.5681   \n",
       "2   1208.4287   \n",
       "3   1006.0121   \n",
       "4  2111.05140   \n",
       "\n",
       "                                                                                                            title  \\\n",
       "0                                              derivations and centroids of four dimensional associative algebras   \n",
       "1                                                              coupled-cluster studies of infinite nuclear matter   \n",
       "2                                                     regularity and uniqueness of the heat ow of biharmonic maps   \n",
       "3                                                          small-scale behaviour in deterministic reaction models   \n",
       "4  two-dimensional phonon polaritons in multilayers of hexagonal boron\\n  nitride from a macroscopic phonon model   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               abstract  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               in this paper, we focus on derivations and centroids of four dimensional\\nassociative algebras. using an existing classification result of low\\ndimensional associative algebras, we describe the derivations and centroids of\\nfour dimensional associative algebras. we also identify algebra(s) that belong\\nto the characteristically nilpotent class among the algebras of four\\ndimensional associative algebras.   \n",
       "1                                                                                                                                                                                                                                                                                  the aim of this work is to develop the relevant formalism for performing\\ncoupled-cluster (cc) calculations in nuclear matter and neutron star matter,\\nincluding thereby important correlations to infinite order in the interaction\\nand testing modern nuclear forces based on chiral effective field theory. our\\nformalism includes the exact treatment of the so-called pauli operator in a\\npartial wave expansion of the equation of state. nuclear and neutron matter\\ncalculations are done using a coupled particle-particle and hole-hole ladder\\napproximation. the coupled ladder equations are derived as an approximation of\\ncc theory, leaving out particle-hole and non-linear diagrams from the cc\\ndoubles amplitude equation. this study is a first step toward cc calculations\\nfor nuclear and neutron matter. we present results for both symmetric nuclear\\nmatter and pure neutron matter employing state-of-the-art nucleon-nucleon\\ninteractions based on chiral effective field theory. we employ also the newly\\noptimized chiral interaction [a. ekstr\\\"om et al., phys. rev. lett. 110, 192502\\n(2013)] to study infinite nuclear matter. the ladder approximation method and\\ncorresponding results are compared with conventional brueckner-hartree-fock\\ntheory.   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      in this paper, we first establish regularity of the heat flow of biharmonic\\nmaps into the unit sphere $s^l\\subset\\mathbb r^{l+1}$ under a smallness\\ncondition of renormalized total energy. for the class of such solutions to the\\nheat flow of biharmonic maps, we prove the properties of uniqueness, convexity\\nof hessian energy, and unique limit at time infinity. we establish both\\nregularity and uniqueness for the class of weak solutions $u$ to the heat flow\\nof biharmonic maps into any compact riemannian manifold $n$ without boundary\\nsuch that $\\nabla^2 u\\in l^q_tl^p_x$ for some $p>n/2$ and $q>2$ satisfying\\n(1.13).   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       in a recent paper published in this journal [j. phys. a: math. theor. 42\\n(2009) 495004] we studied a one-dimensional particles system where nearest\\nparticles attract with a force inversely proportional to a power \\alpha of\\ntheir distance and coalesce upon encounter. numerics yielded a distribution\\nfunction h(z) for the gap between neighbouring particles, with\\nh(z)=z^{\\beta(\\alpha)} for small z and \\beta(\\alpha)>\\alpha. we can now prove\\nanalytically that in the strict limit of z\\to 0, \\beta=\\alpha for \\alpha>0,\\ncorresponding to the mean-field result, and we compute the length scale where\\nmean-field breaks down. more generally, in that same limit correlations are\\nnegligible for any similar reaction model where attractive forces diverge with\\nvanishing distance. the actual meaning of the measured exponent \\beta(\\alpha)\\nremains an open question.   \n",
       "4  phonon polaritons (phps) in freestanding and supported multilayers (muls) of\\nhexagonal boron nitride (hbn) are systematically studied using a macroscopic\\noptical-phonon model. the php properties such as confinement, group velocity,\\npropagation quality factor (pqf) and wavelength scaling are studied. owing to\\nthe nonlocal high-frequency screening, there is an upper frequency limit making\\nthe two-dimensional (2d) phps have a frequency band, and also a maximum pqf\\noccurs near the centre frequency. the substrate's dielectric response should be\\nincluded to accurately calculate the php properties. while the simple\\nelectrostatic approximation (esa) is a proper treatment for php frequencies\\n$\\omega$ above $\\omega_0$ (e.g. $\\omega>1.03\\omega_0$ for the 30-layers;\\n$\\omega_0$ is the $\\gamma$ point optical phonon frequency), it fails to\\ndescribe the php properties near $\\omega_0$ and the effect of retardation\\nshould be included for an accurate description. the php wavelength versus the\\nlayer thickness near $\\omega_0$ deviates significantly from a linear scaling\\nlaw given by the esa due to strong phonon-photon coupling. the calculated php\\ndispersion, pqf and scaling are compared with experimental data of a number of\\nspectroscopic studies and good agreement is obtained. while the frequency of\\nincident light should be near the centre frequency to maximize the pqf, the php\\nwavelength, confinement and propagation length can be engineered by varying the\\nmul thickness and its dielectric environment.   \n",
       "\n",
       "           categories  \\\n",
       "0             math.RA   \n",
       "1             nucl-th   \n",
       "2             math.AP   \n",
       "3  cond-mat.stat-mech   \n",
       "4   cond-mat.mes-hall   \n",
       "\n",
       "                                                    authors  \\\n",
       "0           A.O. Abdulkareem, M.A. Fiidow and I.S. Rakhimov   \n",
       "1  G. Baardsen, A. Ekstr\\\"om, G. Hagen and M. Hjorth-Jensen   \n",
       "2                     Jay Hineman, Tao Huang, Changyou Wang   \n",
       "3                       Paolo Politi and Daniel ben-Avraham   \n",
       "4                                          Jian-zhong Zhang   \n",
       "\n",
       "                                                                                                                                                                      comments  \\\n",
       "0                                                                                     20 pages, 2 tables, Accepted in International Journal of Pure and\\n  Applied Mathematics   \n",
       "1                                                                                                                                                         18 pages, 14 figures   \n",
       "2  Two errors in the proof of proposition 2.2 have been fixed, as a\\n  consequence the range of the power $p$ through the main theorems of the paper\\n  is required to $p>3/2$   \n",
       "3                                                   Six pages. Section 2 has been rewritten. Accepted for publication in\\n  Journal of Physics A: Mathematical and Theoretical   \n",
       "4                                                                                                                                                       18 pages and 9 figures   \n",
       "\n",
       "  update_date  \\\n",
       "0  2017-02-21   \n",
       "1  2013-11-18   \n",
       "2  2012-09-25   \n",
       "3  2010-09-07   \n",
       "4  2022-03-14   \n",
       "\n",
       "                                                                                   cleaned_title  \\\n",
       "0                                       derivation centroid four dimensional associative algebra   \n",
       "1                                                   coupledcluster study infinite nuclear matter   \n",
       "2                                                   regularity uniqueness heat ow biharmonic map   \n",
       "3                                              smallscale behaviour deterministic reaction model   \n",
       "4  twodimensional phonon polaritons multilayers hexagonal boron nitride macroscopic phonon model   \n",
       "\n",
       "                           cleaned_authors cleaned_categories  \\\n",
       "0           ao abdulkareem fiidow rakhimov             mathra   \n",
       "1  g baardsen ekstrom g hagen hjorthjensen             nuclth   \n",
       "2      jay hineman tao huang changyou wang             mathap   \n",
       "3           paolo politi daniel benavraham    condmatstatmech   \n",
       "4                          jianzhong zhang     condmatmeshall   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            cleaned_abstract  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         paper focus derivation centroid four dimensional associative algebra using existing classification result low dimensional associative algebra describe derivation centroid four dimensional associative algebra also identify algebra belong characteristically nilpotent class among algebra four dimensional associative algebra   \n",
       "1                                                                                                                                         aim work develop relevant formalism performing coupledcluster cc calculation nuclear matter neutron star matter including thereby important correlation infinite order interaction testing modern nuclear force based chiral effective field theory formalism includes exact treatment socalled pauli operator partial wave expansion equation state nuclear neutron matter calculation done using coupled particleparticle holehole ladder approximation coupled ladder equation derived approximation cc theory leaving particlehole nonlinear diagram cc double amplitude equation study first step toward cc calculation nuclear neutron matter present result symmetric nuclear matter pure neutron matter employing stateoftheart nucleonnucleon interaction based chiral effective field theory employ also newly optimized chiral interaction ekstrom et al phys rev lett 110 192502 2013 study infinite nuclear matter ladder approximation method corresponding result compared conventional bruecknerhartreefock theory   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         paper first establish regularity heat flow biharmonic map unit sphere slsubsetmathbb rl1 smallness condition renormalized total energy class solution heat flow biharmonic map prove property uniqueness convexity hessian energy unique limit time infinity establish regularity uniqueness class weak solution u heat flow biharmonic map compact riemannian manifold n without boundary nabla2 uin lqtlpx pn2 q2 satisfying 113   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    recent paper published journal j phys math theor 42 2009 495004 studied onedimensional particle system nearest particle attract force inversely proportional power alpha distance coalesce upon encounter numerics yielded distribution function hz gap neighbouring particle hzzbetaalpha small z betaalphaalpha prove analytically strict limit zto 0 betaalpha alpha0 corresponding meanfield result compute length scale meanfield break generally limit correlation negligible similar reaction model attractive force diverge vanishing distance actual meaning measured exponent betaalpha remains open question   \n",
       "4  phonon polaritons phps freestanding supported multilayers muls hexagonal boron nitride hbn systematically studied using macroscopic opticalphonon model php property confinement group velocity propagation quality factor pqf wavelength scaling studied owing nonlocal highfrequency screening upper frequency limit making twodimensional 2d phps frequency band also maximum pqf occurs near centre frequency substrate dielectric response included accurately calculate php property simple electrostatic approximation esa proper treatment php frequency omega omega0 eg omega103omega0 30layers omega0 gamma point optical phonon frequency fails describe php property near omega0 effect retardation included accurate description php wavelength versus layer thickness near omega0 deviate significantly linear scaling law given esa due strong phononphoton coupling calculated php dispersion pqf scaling compared experimental data number spectroscopic study good agreement obtained frequency incident light near centre frequency maximize pqf php wavelength confinement propagation length engineered varying mul thickness dielectric environment   \n",
       "\n",
       "                                                                                 cleaned_comments  \\\n",
       "0                         20 page 2 table accepted international journal pure applied mathematics   \n",
       "1                                                                               18 page 14 figure   \n",
       "2  two error proof proposition 22 fixed consequence range power p main theorem paper required p32   \n",
       "3       six page section 2 rewritten accepted publication journal physic mathematical theoretical   \n",
       "4                                                                                18 page 9 figure   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  enhanced_text  \n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Title: derivation centroid four dimensional associative algebra [SEP] Authors: ao abdulkareem fiidow rakhimov [SEP] Categories: mathra [SEP] Abstract: paper focus derivation centroid four dimensional associative algebra using existing classification result low dimensional associative algebra describe derivation centroid four dimensional associative algebra also identify algebra belong characteristically nilpotent class among algebra four dimensional associative algebra [SEP] Comments: 20 page 2 table accepted international journal pure applied mathematics [SEP] Updated on: 2017-02-21  \n",
       "1                                                                                                                                                                         Title: coupledcluster study infinite nuclear matter [SEP] Authors: g baardsen ekstrom g hagen hjorthjensen [SEP] Categories: nuclth [SEP] Abstract: aim work develop relevant formalism performing coupledcluster cc calculation nuclear matter neutron star matter including thereby important correlation infinite order interaction testing modern nuclear force based chiral effective field theory formalism includes exact treatment socalled pauli operator partial wave expansion equation state nuclear neutron matter calculation done using coupled particleparticle holehole ladder approximation coupled ladder equation derived approximation cc theory leaving particlehole nonlinear diagram cc double amplitude equation study first step toward cc calculation nuclear neutron matter present result symmetric nuclear matter pure neutron matter employing stateoftheart nucleonnucleon interaction based chiral effective field theory employ also newly optimized chiral interaction ekstrom et al phys rev lett 110 192502 2013 study infinite nuclear matter ladder approximation method corresponding result compared conventional bruecknerhartreefock theory [SEP] Comments: 18 page 14 figure [SEP] Updated on: 2013-11-18  \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Title: regularity uniqueness heat ow biharmonic map [SEP] Authors: jay hineman tao huang changyou wang [SEP] Categories: mathap [SEP] Abstract: paper first establish regularity heat flow biharmonic map unit sphere slsubsetmathbb rl1 smallness condition renormalized total energy class solution heat flow biharmonic map prove property uniqueness convexity hessian energy unique limit time infinity establish regularity uniqueness class weak solution u heat flow biharmonic map compact riemannian manifold n without boundary nabla2 uin lqtlpx pn2 q2 satisfying 113 [SEP] Comments: two error proof proposition 22 fixed consequence range power p main theorem paper required p32 [SEP] Updated on: 2012-09-25  \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Title: smallscale behaviour deterministic reaction model [SEP] Authors: paolo politi daniel benavraham [SEP] Categories: condmatstatmech [SEP] Abstract: recent paper published journal j phys math theor 42 2009 495004 studied onedimensional particle system nearest particle attract force inversely proportional power alpha distance coalesce upon encounter numerics yielded distribution function hz gap neighbouring particle hzzbetaalpha small z betaalphaalpha prove analytically strict limit zto 0 betaalpha alpha0 corresponding meanfield result compute length scale meanfield break generally limit correlation negligible similar reaction model attractive force diverge vanishing distance actual meaning measured exponent betaalpha remains open question [SEP] Comments: six page section 2 rewritten accepted publication journal physic mathematical theoretical [SEP] Updated on: 2010-09-07  \n",
       "4  Title: twodimensional phonon polaritons multilayers hexagonal boron nitride macroscopic phonon model [SEP] Authors: jianzhong zhang [SEP] Categories: condmatmeshall [SEP] Abstract: phonon polaritons phps freestanding supported multilayers muls hexagonal boron nitride hbn systematically studied using macroscopic opticalphonon model php property confinement group velocity propagation quality factor pqf wavelength scaling studied owing nonlocal highfrequency screening upper frequency limit making twodimensional 2d phps frequency band also maximum pqf occurs near centre frequency substrate dielectric response included accurately calculate php property simple electrostatic approximation esa proper treatment php frequency omega omega0 eg omega103omega0 30layers omega0 gamma point optical phonon frequency fails describe php property near omega0 effect retardation included accurate description php wavelength versus layer thickness near omega0 deviate significantly linear scaling law given esa due strong phononphoton coupling calculated php dispersion pqf scaling compared experimental data number spectroscopic study good agreement obtained frequency incident light near centre frequency maximize pqf php wavelength confinement propagation length engineered varying mul thickness dielectric environment [SEP] Comments: 18 page 9 figure [SEP] Updated on: 2022-03-14  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wGK-jx6zkr12"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('enhanced_stratified_sample_train.csv')\n",
    "val_df = pd.read_csv('val_df.csv')\n",
    "test_df = pd.read_csv('test_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating TF-IDF Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8kzevRi0kUqh"
   },
   "outputs": [],
   "source": [
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10000, stop_words='english')\n",
    "tfidf_train_matrix = tfidf_vectorizer.fit_transform(train_df['enhanced_text'])\n",
    "# tfidf_val_matrix = tfidf_vectorizer.transform(val_df['abstract_cleaned'])\n",
    "# tfidf_test_matrix = tfidf_vectorizer.transform(test_df['abstract_cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "G0uwkkOYlMd3"
   },
   "outputs": [],
   "source": [
    "# Recommendation Function\n",
    "def recommend_tfidf(query_abstract, top_k=5):\n",
    "    # Transform query into TF-IDF vector\n",
    "    query_vector = tfidf_vectorizer.transform([query_abstract])\n",
    "\n",
    "    # Compute cosine similarities with train set\n",
    "    similarities = cosine_similarity(query_vector, tfidf_train_matrix).flatten()\n",
    "\n",
    "    # Get top-k indices\n",
    "    top_indices = similarities.argsort()[-top_k:][::-1]\n",
    "    top_scores = similarities[top_indices]\n",
    "    # Return top-k rows from the train_df\n",
    "    return train_df.iloc[top_indices],top_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "CHU5Be2kk6QB"
   },
   "outputs": [],
   "source": [
    "def precision_at_k(recommendations, true_category, k):\n",
    "    relevant = sum(1 for category in recommendations[\"categories\"].tolist() if category == true_category)\n",
    "    return relevant / k\n",
    "def recall_at_k(recommendations, true_category, all_relevant_count, k):\n",
    "    relevant = sum(1 for category in recommendations[\"categories\"].tolist() if category == true_category)\n",
    "    return relevant / all_relevant_count if all_relevant_count > 0 else 0\n",
    "def mean_reciprocal_rank(recommendations, true_category):\n",
    "    for i, category in enumerate(recommendations[\"categories\"].tolist()):\n",
    "        if category == true_category:\n",
    "            return 1 / (i + 1)  # Rank is 1-based\n",
    "    return 0  # No relevant document found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DAD9YbzKlfhQ"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define custom schema with vector as FixedSizeList\n",
    "vector_dim = 10000  # Replace with the actual dimension of your TF-IDF vectors\n",
    "custom_schema = pa.schema([\n",
    "    pa.field(\"id\", pa.int32()),\n",
    "    pa.field(\"vector\", pa.list_(pa.float32(), vector_dim)),  # FixedSizeList for vectors\n",
    "    pa.field(\"title\", pa.string()),\n",
    "    pa.field(\"categories\", pa.string()),\n",
    "    pa.field(\"abstract\", pa.string()),\n",
    "    pa.field(\"authors\",pa.string()),\n",
    "    pa.field(\"comments\",pa.string()),\n",
    "    pa.field(\"update_date\",pa.string()),\n",
    "    pa.field(\"enhanced_text\",pa.string())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the schema for storing the TF-IDF Vectors in LanceDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2cFG3sE1mIFy"
   },
   "outputs": [],
   "source": [
    "# Assume tfidf_train_matrix and train_df are defined\n",
    "tfidf_vectors = tfidf_train_matrix.toarray().astype('float32')\n",
    "\n",
    "# Define the batch size\n",
    "batch_size = 500  # Adjust based on your system's memory capacity\n",
    "\n",
    "# Connect to LanceDB\n",
    "db = lancedb.connect(\"lancedb_directory\")\n",
    "\n",
    "# Create or open the table in LanceDB\n",
    "tbl = db.create_table(\"tfidf_vectors\", schema=custom_schema, mode=\"overwrite\")\n",
    "\n",
    "# Prepare for batch insertion\n",
    "batch_data = []\n",
    "\n",
    "# Convert train_df to a list of records for efficient iteration\n",
    "train_records = train_df.to_dict(orient=\"records\")\n",
    "\n",
    "for idx, (vector, row) in enumerate(zip(tfidf_vectors, train_records)):\n",
    "    record = {\n",
    "        \"id\": idx,\n",
    "        \"vector\": vector.tolist(),\n",
    "        \"title\": row[\"title\"],\n",
    "        \"categories\": row[\"categories\"],\n",
    "        \"abstract\": row[\"abstract\"],\n",
    "        \"authors\": row[\"authors\"],\n",
    "        \"comments\": row[\"comments\"],\n",
    "        \"update_date\": row[\"update_date\"],\n",
    "        \"enhanced_text\": row[\"enhanced_text\"]\n",
    "    }\n",
    "    batch_data.append(record)\n",
    "\n",
    "    # Insert batch when the specified size is reached\n",
    "    if len(batch_data) == batch_size:\n",
    "        batch_df = pd.DataFrame(batch_data)\n",
    "        tbl.add(batch_df)\n",
    "        batch_data = []  # Clear the batch_data list\n",
    "\n",
    "# Insert any remaining data after the loop\n",
    "if batch_data:\n",
    "    batch_df = pd.DataFrame(batch_data)\n",
    "    tbl.add(batch_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning & preprocessing the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PK4zNs9-pAjx",
    "outputId": "53ac44b0-0561-4d70-dade-4456bf4ff78d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\prern\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\prern\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\prern\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download NLTK resources if not already downloaded\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# Load the stratified sample dataset\n",
    "df = pd.read_csv('test_df.csv')\n",
    "\n",
    "# Initialize stopwords and lemmatizer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    if pd.isnull(text):\n",
    "        return \"\"\n",
    "    # Lowercasing\n",
    "    text = text.lower()\n",
    "    # Remove special characters and punctuation\n",
    "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
    "    # Remove extra whitespace and newlines\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    # Tokenize and remove stopwords, then lemmatize\n",
    "    tokens = text.split()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "\n",
    "df['cleaned_abstract'] = df['abstract'].apply(clean_text)\n",
    "\n",
    "\n",
    "test_df = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "cYeW5FOjpNRz"
   },
   "outputs": [],
   "source": [
    "tfidf_test_matrix = tfidf_vectorizer.transform(test_df['cleaned_abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "jhP7txvhmgBy",
    "outputId": "cb539da0-1594-43e0-f64a-5106e714c9f3"
   },
   "outputs": [],
   "source": [
    "# from tqdm import tqdm  # For progress tracking\n",
    "\n",
    "# # Precompute category counts in the training data\n",
    "# category_counts = train_df[\"categories\"].value_counts().to_dict()\n",
    "\n",
    "# # Initialize metrics\n",
    "# total_precision = 0\n",
    "# total_recall = 0\n",
    "# total_mrr = 0\n",
    "# num_queries = len(test_df)\n",
    "\n",
    "# # Process queries in batches\n",
    "# batch_size = 500  # Adjust based on available memory\n",
    "# for start in tqdm(range(0, num_queries, batch_size), desc=\"Processing Batches\"):\n",
    "#     end = min(start + batch_size, num_queries)\n",
    "\n",
    "#     # Extract batch vectors and true categories\n",
    "#     batch_vectors = tfidf_test_matrix[start:end].toarray()\n",
    "#     batch_categories = test_df.iloc[start:end][\"categories\"].values\n",
    "\n",
    "#     for idx, (query_vector, true_category) in enumerate(zip(batch_vectors, batch_categories)):\n",
    "#         # Generate recommendations\n",
    "#         recommendations = tbl.search(query_vector).metric(\"cosine\").limit(5).to_pandas()  # Efficient LanceDB search\n",
    "\n",
    "#         # Compute metrics\n",
    "#         precision = precision_at_k(recommendations, true_category, k=5)\n",
    "#         all_relevant_count = category_counts.get(true_category, 0)\n",
    "#         recall = recall_at_k(recommendations, true_category, all_relevant_count, k=5)\n",
    "#         mrr = mean_reciprocal_rank(recommendations, true_category)\n",
    "\n",
    "#         total_precision += precision\n",
    "#         total_recall += recall\n",
    "#         total_mrr += mrr\n",
    "\n",
    "#         # Log details for the current query\n",
    "#         print(f\"Processed Query {start + idx + 1}/{num_queries}:\")\n",
    "#         print(f\" - True Category: {true_category}\")\n",
    "#         print(f\" - Recommendations: {recommendations[['categories', 'title']]}\")\n",
    "#         print(f\" - Precision@5: {precision:.2f}, Recall@5: {recall:.2f}, MRR: {mrr:.2f}\")\n",
    "\n",
    "# # Average metrics\n",
    "# avg_precision = total_precision / num_queries\n",
    "# avg_recall = total_recall / num_queries\n",
    "# avg_mrr = total_mrr / num_queries\n",
    "\n",
    "# print(\"\\nFinal Metrics:\")\n",
    "# print(f\"Average Precision@5: {avg_precision:.2f}\")\n",
    "# print(f\"Average Recall@5: {avg_recall:.2f}\")\n",
    "# print(f\"Average MRR: {avg_mrr:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Testing with all the ground truth measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ltnSLZm5pZ9z"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|| 30/30 [2:01:40<00:00, 243.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Metrics:\n",
      "\n",
      "Category Ground Truth:\n",
      " - Average Precision@5: 0.44\n",
      " - Average Recall@5: 0.00\n",
      " - Average MRR: 0.60\n",
      "\n",
      "Clustering Ground Truth:\n",
      " - Average Precision@5: 0.00\n",
      " - Average Recall@5: 0.00\n",
      " - Average MRR: 0.00\n",
      "\n",
      "Similarity Ground Truth:\n",
      " - Average Precision@5: 0.00\n",
      " - Average Recall@5: 0.00\n",
      " - Average MRR: 0.60\n",
      "\n",
      "Temporal Ground Truth:\n",
      " - Average Precision@5: 0.18\n",
      " - Average Recall@5: 0.00\n",
      " - Average MRR: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Precompute category counts in the training data\n",
    "category_counts = train_df[\"categories\"].value_counts().to_dict()\n",
    "\n",
    "# Perform clustering on train embeddings (for clustering ground truth)\n",
    "num_clusters = 20  # Adjust as needed\n",
    "train_embeddings = tfidf_train_matrix.toarray()  # Or use SBERT embeddings\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "train_df['cluster'] = kmeans.fit_predict(train_embeddings)\n",
    "\n",
    "# Initialize metrics for each ground truth method\n",
    "metrics = {\n",
    "    \"category\": {\"precision\": 0, \"recall\": 0, \"mrr\": 0},\n",
    "    \"clustering\": {\"precision\": 0, \"recall\": 0, \"mrr\": 0},\n",
    "    \"similarity\": {\"precision\": 0, \"recall\": 0, \"mrr\": 0},\n",
    "    \"temporal\": {\"precision\": 0, \"recall\": 0, \"mrr\": 0},\n",
    "}\n",
    "\n",
    "# Define similarity threshold and temporal parameters\n",
    "similarity_threshold = 0.7\n",
    "time_window_days = 365  # 1-year window for temporal evaluation\n",
    "weights = {\"category\": 0.3, \"cluster\": 0.2, \"similarity\": 0.3, \"temporal\": 0.2}\n",
    "\n",
    "# Number of queries\n",
    "num_queries = len(test_df)\n",
    "\n",
    "# Functions for different ground truth evaluations\n",
    "def precision_at_k(recommendations, true_label, k=5):\n",
    "    relevant = sum(1 for label in recommendations[\"categories\"].tolist()[:k] if label == true_label)\n",
    "    return relevant / k\n",
    "\n",
    "def recall_at_k(recommendations, true_label, all_relevant_count, k=5):\n",
    "    relevant = sum(1 for label in recommendations[\"categories\"].tolist()[:k] if label == true_label)\n",
    "    return relevant / all_relevant_count if all_relevant_count > 0 else 0\n",
    "\n",
    "def mean_reciprocal_rank(recommendations, true_label):\n",
    "    for i, label in enumerate(recommendations[\"categories\"].tolist()):\n",
    "        if label == true_label:\n",
    "            return 1 / (i + 1)\n",
    "    return 0\n",
    "\n",
    "def temporal_score(query_date, rec_date, window=time_window_days):\n",
    "    rec_date = pd.to_datetime(rec_date, errors='coerce')\n",
    "    return 1 if pd.notnull(rec_date) and abs((query_date - rec_date).days) <= window else 0\n",
    "\n",
    "def process_query(query_vector, true_category, query_date):\n",
    "    result = {\n",
    "        \"category\": {\"precision\": 0, \"recall\": 0, \"mrr\": 0},\n",
    "        \"clustering\": {\"precision\": 0, \"recall\": 0, \"mrr\": 0},\n",
    "        \"similarity\": {\"precision\": 0, \"recall\": 0, \"mrr\": 0},\n",
    "        \"temporal\": {\"precision\": 0, \"recall\": 0, \"mrr\": 0},\n",
    "    }\n",
    "    \n",
    "    # Generate recommendations\n",
    "    recommendations = tbl.search(query_vector).metric(\"cosine\").limit(5).to_pandas()\n",
    "    recommendation_vectors = np.vstack(recommendations['vector'].tolist())\n",
    "\n",
    "    # Category-Based Evaluation\n",
    "    all_relevant_count = category_counts.get(true_category, 0)\n",
    "    result[\"category\"][\"precision\"] = precision_at_k(recommendations, true_category, k=5)\n",
    "    result[\"category\"][\"recall\"] = recall_at_k(recommendations, true_category, all_relevant_count, k=5)\n",
    "    result[\"category\"][\"mrr\"] = mean_reciprocal_rank(recommendations, true_category)\n",
    "\n",
    "    # Clustering-Based Evaluation\n",
    "    true_cluster = train_df[train_df[\"categories\"] == true_category][\"cluster\"].iloc[0]\n",
    "    result[\"clustering\"][\"precision\"] = precision_at_k(recommendations, true_cluster, k=5)\n",
    "    result[\"clustering\"][\"recall\"] = recall_at_k(recommendations, true_cluster, all_relevant_count, k=5)\n",
    "    result[\"clustering\"][\"mrr\"] = mean_reciprocal_rank(recommendations, true_cluster)\n",
    "\n",
    "    # Similarity-Based Evaluation\n",
    "    cosine_similarities = cosine_similarity(query_vector.reshape(1, -1), recommendation_vectors)[0]\n",
    "    relevant_similar = sum(1 for score in cosine_similarities[:5] if score >= similarity_threshold)\n",
    "    result[\"similarity\"][\"precision\"] = relevant_similar / 5\n",
    "    result[\"similarity\"][\"recall\"] = relevant_similar / all_relevant_count if all_relevant_count > 0 else 0\n",
    "    result[\"similarity\"][\"mrr\"] = mean_reciprocal_rank(recommendations, true_category)\n",
    "\n",
    "    # Temporal-Based Evaluation\n",
    "    relevant_temporal = sum(1 for rec_date in recommendations[\"update_date\"][:5] if temporal_score(query_date, rec_date))\n",
    "    result[\"temporal\"][\"precision\"] = relevant_temporal / 5\n",
    "    result[\"temporal\"][\"recall\"] = relevant_temporal / all_relevant_count if all_relevant_count > 0 else 0\n",
    "    result[\"temporal\"][\"mrr\"] = mean_reciprocal_rank(recommendations, true_category)\n",
    "\n",
    "    return result\n",
    "\n",
    "# Process queries in batches with parallel processing\n",
    "batch_size = 500\n",
    "for start in tqdm(range(0, num_queries, batch_size), desc=\"Processing Batches\"):\n",
    "    end = min(start + batch_size, num_queries)\n",
    "\n",
    "    # Extract batch vectors and true categories\n",
    "    batch_vectors = tfidf_test_matrix[start:end].toarray()\n",
    "    batch_categories = test_df.iloc[start:end][\"categories\"].values\n",
    "    batch_dates = pd.to_datetime(test_df.iloc[start:end][\"update_date\"], errors='coerce').values\n",
    "\n",
    "    # Parallel processing of each query in the batch\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = [executor.submit(process_query, query_vector, true_category, query_date)\n",
    "                   for query_vector, true_category, query_date in zip(batch_vectors, batch_categories, batch_dates)]\n",
    "        \n",
    "        for future in as_completed(futures):\n",
    "            result = future.result()\n",
    "            for key in metrics:\n",
    "                for metric in metrics[key]:\n",
    "                    metrics[key][metric] += result[key][metric]\n",
    "\n",
    "# Compute average metrics\n",
    "for method in metrics:\n",
    "    metrics[method][\"precision\"] /= num_queries\n",
    "    metrics[method][\"recall\"] /= num_queries\n",
    "    metrics[method][\"mrr\"] /= num_queries\n",
    "\n",
    "# Display final metrics\n",
    "print(\"\\nFinal Metrics:\")\n",
    "for method, scores in metrics.items():\n",
    "    print(f\"\\n{method.capitalize()} Ground Truth:\")\n",
    "    print(f\" - Average Precision@5: {scores['precision']:.2f}\")\n",
    "    print(f\" - Average Recall@5: {scores['recall']:.2f}\")\n",
    "    print(f\" - Average MRR: {scores['mrr']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "tLrq4GLXtH7L"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top Recommendations:\n",
      "\n",
      "Title: diversifying sample generation for accurate data-free quantization\n",
      "Category: cscv\n",
      "Similarity Score: 0.3478\n",
      "\n",
      "Title: quantized w-algebra of ${\\frak sl}(2,1)$ : a construction from the\n",
      "  quantization of screening operators\n",
      "Category: mathqa\n",
      "Similarity Score: 0.2876\n",
      "\n",
      "Title: training deep networks with synthetic data: bridging the reality gap by\n",
      "  domain randomization\n",
      "Category: cscv\n",
      "Similarity Score: 0.2839\n",
      "\n",
      "Title: splitting of a doubly quantized vortex through intertwining in\n",
      "  bose-einstein condensates\n",
      "Category: condmatsoft\n",
      "Similarity Score: 0.2675\n",
      "\n",
      "Title: towards semi-supervised learning of automatic post-editing:\n",
      "  data-synthesis by infilling mask with erroneous tokens\n",
      "Category: cscl\n",
      "Similarity Score: 0.2671\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Function to get recommendations for a manual abstract input\n",
    "def get_recommendations(manual_abstract, top_k=5):\n",
    "    # Convert the manual abstract to a TF-IDF vector\n",
    "    query_vector = tfidf_vectorizer.transform([manual_abstract])\n",
    "\n",
    "    # Compute cosine similarity between the query vector and the training embeddings\n",
    "    similarities = cosine_similarity(query_vector, tfidf_train_matrix)[0]\n",
    "\n",
    "    # Get the indices of the top_k most similar entries\n",
    "    top_indices = similarities.argsort()[::-1][:top_k]\n",
    "\n",
    "    # Retrieve the recommended titles, abstracts, and similarity scores\n",
    "    recommendations = train_df.iloc[top_indices][['title', 'cleaned_abstract','cleaned_categories']]\n",
    "    recommendations['similarity_score'] = similarities[top_indices]\n",
    "\n",
    "    return recommendations\n",
    "\n",
    "# Manually provide an abstract\n",
    "manual_abstract = \"\"\"zeroshot quantization zsq promising compressing accelerating deep neural networks data training fullprecision models inaccessible zsq network quantization performed using synthetic samples performance quantized models depends heavily quality synthetic samples nonetheless synthetic samples constructed existing zsq methods easily fitted models accordingly quantized models obtained methods suffer significant performance degradation hard samples address issue propose hard sample synthesizing training hast specifically hast pays attention hard samples synthesizing samples makes synthetic samples hard fit training quantized models hast aligns features extracted fullprecision quantized models ensure similarity features extracted models extensive experiments hast significantly outperforms existing zsq methods achieving performance comparable models quantizedrealdata\"\"\"\n",
    "\n",
    "# Get the top 5 recommendations\n",
    "top_recommendations = get_recommendations(manual_abstract, top_k=5)\n",
    "\n",
    "# Display the recommendations\n",
    "print(\"\\nTop Recommendations:\")\n",
    "for idx, row in top_recommendations.iterrows():\n",
    "    print(f\"\\nTitle: {row['title']}\")\n",
    "    print(f\"Category: {row['cleaned_categories']}\")\n",
    "    print(f\"Similarity Score: {row['similarity_score']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
